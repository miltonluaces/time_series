{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent pattern for data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml import fpm\n",
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP Growth algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkContext(\"local\", \"sqlContext\")\n",
    "sql = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         items\n",
       "0   0     [1, 2, 5]\n",
       "1   1  [1, 2, 3, 5]\n",
       "2   2        [1, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sql.createDataFrame([(0, [1, 2, 5]),(1, [1, 2, 3, 5]),(2, [1, 2])], [\"id\", \"items\"])\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpg = fpm.FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "fpg_fit = fpg.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Frequent itemsets\n",
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [5]|   2|\n",
      "|   [5, 2]|   2|\n",
      "|[5, 2, 1]|   2|\n",
      "|   [5, 1]|   2|\n",
      "|      [2]|   3|\n",
      "|   [2, 1]|   3|\n",
      "|      [1]|   3|\n",
      "+---------+----+\n",
      "\n",
      "2. Association rules\n",
      "+----------+----------+------------------+----+\n",
      "|antecedent|consequent|        confidence|lift|\n",
      "+----------+----------+------------------+----+\n",
      "|    [5, 2]|       [1]|               1.0| 1.0|\n",
      "|    [5, 1]|       [2]|               1.0| 1.0|\n",
      "|       [5]|       [2]|               1.0| 1.0|\n",
      "|       [5]|       [1]|               1.0| 1.0|\n",
      "|       [2]|       [5]|0.6666666666666666| 1.0|\n",
      "|       [2]|       [1]|               1.0| 1.0|\n",
      "|       [1]|       [5]|0.6666666666666666| 1.0|\n",
      "|       [1]|       [2]|               1.0| 1.0|\n",
      "|    [2, 1]|       [5]|0.6666666666666666| 1.0|\n",
      "+----------+----------+------------------+----+\n",
      "\n",
      "3. Exam the input items against all the association rules and summarize the consequents as prediction\n",
      "+---+------------+----------+\n",
      "| id|       items|prediction|\n",
      "+---+------------+----------+\n",
      "|  0|   [1, 2, 5]|        []|\n",
      "|  1|[1, 2, 3, 5]|        []|\n",
      "|  2|      [1, 2]|       [5]|\n",
      "+---+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1. Frequent itemsets')\n",
    "fpg_fit.freqItemsets.show()\n",
    "\n",
    "print('2. Association rules')\n",
    "fpg_fit.associationRules.show()\n",
    "\n",
    "print('3. Exam the input items against all the association rules and summarize the consequents as prediction')\n",
    "fpg_fit.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|items                   |\n",
      "+------------------------+\n",
      "|[r, z, h, k, p]         |\n",
      "|[z, y, x, w, v, u, t, s]|\n",
      "|[s, x, o, n, r]         |\n",
      "|[x, z, y, m, t, s, q, e]|\n",
      "|[z]                     |\n",
      "|[x, z, y, r, q, t, p]   |\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/ProgramFiles/Spark/spark-3.0.0-bin-hadoop2.7/data/mllib/'\n",
    "rdd = (sql.read.text(path + \"sample_fpgrowth.txt\").select(split(\"value\", \"\\s+\").alias(\"items\")))\n",
    "rdd.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = fpm.FPGrowth(minSupport=0.2, minConfidence=0.7)\n",
    "fp_fit = fp.fit(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [s]|   3|\n",
      "|   [s, x]|   3|\n",
      "|[s, x, z]|   2|\n",
      "|   [s, z]|   2|\n",
      "|      [r]|   3|\n",
      "+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fp_fit.setPredictionCol(\"newPrediction\")\n",
    "fp_fit.freqItemsets.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix span algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1, 2], [3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[1], [3, 2], [1, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1, 2], [5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[6]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sequence\n",
       "0          [[1, 2], [3]]\n",
       "1  [[1], [3, 2], [1, 2]]\n",
       "2          [[1, 2], [5]]\n",
       "3                  [[6]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.parallelize([Row(sequence=[[1, 2], [3]]), Row(sequence=[[1], [3, 2], [1, 2]]), Row(sequence=[[1, 2], [5]]), Row(sequence=[[6]])]).toDF()\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|  sequence|freq|\n",
      "+----------+----+\n",
      "|     [[1]]|   3|\n",
      "|     [[3]]|   2|\n",
      "|     [[2]]|   3|\n",
      "|  [[1, 2]]|   3|\n",
      "|[[1], [3]]|   2|\n",
      "+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefixSpan = PrefixSpan(minSupport=0.5, maxPatternLength=5, maxLocalProjDBSize=32000000)\n",
    "\n",
    "# Find frequent sequential patterns.\n",
    "prefixSpan.findFrequentSequentialPatterns(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitc33de82c9da04edea88eb124459bf44a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
