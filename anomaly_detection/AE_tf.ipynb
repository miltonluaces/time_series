{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE Autoencoders\n",
    "### From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(object):\n",
    "\n",
    "    # Fields\n",
    "    nHidden = 2\n",
    "    epochs = 1000\n",
    "    batchSize = 10\n",
    "    Whid = None\n",
    "    bhid = None\n",
    "    Hout = None\n",
    "    Wout = None\n",
    "    bout = None\n",
    "    \n",
    "    Yout = None\n",
    "    Yexp = None\n",
    "    Out = None\n",
    "    inputOrig = None\n",
    "    input = None\n",
    "    output = None\n",
    "    nSamp = 0\n",
    "    nVar = 3\n",
    "    X = tf.placeholder(\"float\", [None, nVar]) \n",
    " \n",
    "    \n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        return\n",
    "      \n",
    "    # Normalize to [0,1] \n",
    "    def Norm01(self, data):\n",
    "        nData = np.divide((data-data.min()), (data.max() - data.min())) \n",
    "        return nData\n",
    "    \n",
    "    # Normalize to [-1,1] \n",
    "    def Norm_11(self, data):\n",
    "        nData = np.divide((data-data.min()), (data.max() - data.min())) \n",
    "        n1Data = (nData*2)-1 \n",
    "        return n1Data\n",
    "\n",
    "    def Build(self, input): \n",
    "         \n",
    "        # Normalization (in this case [-1,1]\n",
    "        self.inputOrig = input\n",
    "        output = input \n",
    "        self.input = self.Norm_11(input) \n",
    "        self.output = self.Norm_11(output) \n",
    "         \n",
    "        self.nSamp, self.nVar = self.input.shape  \n",
    "        self.batchSize = min(self.batchSize, self.nSamp) \n",
    "        \n",
    "        # input layer\n",
    "        self.X = tf.placeholder(\"float\", [None, self.nVar]) \n",
    "       \n",
    "        # hidden layer \n",
    "        self.Whid = tf.Variable(tf.random_uniform((self.nVar, self.nHidden), -1.0 / math.sqrt(self.nVar), 1.0 / math.sqrt(self.nVar))) \n",
    "        self.bhid = tf.Variable(tf.zeros([self.nHidden])) \n",
    "        self.Yhid = tf.nn.tanh(tf.matmul(self.X,self.Whid) + self.bhid) \n",
    "        \n",
    "        # output layer\n",
    "        self.Wout = tf.transpose(self.Whid) # tied weights \n",
    "        self.bout = tf.Variable(tf.zeros([self.nVar])) \n",
    "        self.Yout = tf.nn.tanh(tf.matmul(self.Yhid,self.Wout) + self.bout) \n",
    "        \n",
    "        # expected outcome\n",
    "        self.Yexp = tf.placeholder(\"float\", [None,self.nVar]) \n",
    "        return\n",
    "    \n",
    "    def Train(self, log=False): \n",
    "        \n",
    "        mse = tf.reduce_mean(tf.square(self.Yout - self.Yexp)) #crossEntropy = -tf.reduce_sum(self.Yexp * tf.log(self.Yout)) \n",
    "        trainStep = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(mse) \n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session() \n",
    "        sess.run(init) \n",
    "   \n",
    "        for i in range(self.epochs): \n",
    "            sample = np.random.randint(self.nSamp, size=self.batchSize) \n",
    "            bX = self.input[sample][:] \n",
    "            bY = self.output[sample][:] \n",
    "            sess.run(trainStep, feed_dict={self.X: bX, self.Yexp:bY}) \n",
    "            if i % 100 == 0 and log==True: \n",
    "                Mse = sess.run(mse, feed_dict={self.X: bX, self.Yexp:bY}); print(i, \" : \", round(Mse,5)) \n",
    "        self.Out = sess.run(self.Yout, feed_dict={self.X: self.input})\n",
    "        return\n",
    "    \n",
    "    def Output(self):\n",
    "        #print(\"Expected:\"); print(self.output) \n",
    "        #print( \"Output:\"); print(np.round(self.Out, 2)); \n",
    "        diff = np.square(self.output - self.Out); \n",
    "        M = np.mean(pd.DataFrame(diff), axis=1); \n",
    "        Mm = M.as_matrix().reshape(M.shape[0], 1)\n",
    "        res = np.append(self.inputOrig, Mm, axis=1); print(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AE\n",
      "[[2.000 1.000 1.000 2.000]\n",
      " [-2.000 1.000 -1.000 2.000]\n",
      " [0.000 1.000 0.000 2.000]\n",
      " [0.000 -1.000 0.000 -2.000]\n",
      " [0.000 -1.000 0.000 -2.000]]\n",
      "0  :  0.30752\n",
      "100  :  0.08963\n",
      "200  :  0.02\n",
      "300  :  0.00785\n",
      "400  :  0.00454\n",
      "500  :  0.00478\n",
      "600  :  0.00319\n",
      "700  :  0.00256\n",
      "800  :  0.00328\n",
      "900  :  0.00267\n",
      "[[2.000 1.000 1.000 2.000 0.004]\n",
      " [-2.000 1.000 -1.000 2.000 0.004]\n",
      " [0.000 1.000 0.000 2.000 0.001]\n",
      " [0.000 -1.000 0.000 -2.000 0.002]\n",
      " [0.000 -1.000 0.000 -2.000 0.002]]\n",
      "[[2.000 1.000 1.000 2.000 0.004]\n",
      " [-2.000 1.000 -1.000 2.000 0.004]\n",
      " [0.000 1.000 0.000 2.000 0.001]\n",
      " [0.000 -1.000 0.000 -2.000 0.002]\n",
      " [0.000 -1.000 0.000 -2.000 0.002]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:92: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "        \n",
    "print (\"Test AE\")\n",
    "\n",
    "input = np.array([[2.0, 1.0, 1.0, 2.0], [-2.0, 1.0, -1.0, 2.0], [0.0, 1.0, 0.0, 2.0], [0.0, -1.0, 0.0, -2.0], [0.0, -1.0, 0.0, -2.0]]) \n",
    "print(input) \n",
    "\n",
    "ae = AE()\n",
    "ae.Build(input)\n",
    "ae.Train(True)\n",
    "res = ae.Output()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import AE as Ae\n",
    "import MNIST_data.inputData as id\n",
    "\n",
    "\n",
    "# Test TsCat, transforming numerical time series in categorical\n",
    "# -------------------------------------------------------------------\n",
    "   \n",
    "class AETest(unittest.TestCase):\n",
    "\n",
    "    # Setup & TearDown\n",
    "    # ---------------------------------------------------------------\n",
    "    \n",
    "    def setUp(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def tearDown(self):\n",
    "        pass\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        #import sys;sys.argv = ['', 'Test.testName']\n",
    "        unittest.main()\n",
    "        \n",
    " # Tests AE: Test BinVar and BinTS\n",
    " # ---------------------------------------------------------------\n",
    "    \n",
    "    def testAE(self):\n",
    "        np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "        \n",
    "        print (\"Test AE\")\n",
    "        \n",
    "        input = np.array([[2.0, 1.0, 1.0, 2.0], [-2.0, 1.0, -1.0, 2.0], [0.0, 1.0, 0.0, 2.0], [0.0, -1.0, 0.0, -2.0], [0.0, -1.0, 0.0, -2.0]]) ; print(input) \n",
    "        ae = Ae.AE()\n",
    "        ae.Build(input)\n",
    "        ae.Train(True)\n",
    "        res = ae.Output()\n",
    "        print(res)\n",
    "        pass\n",
    "\n",
    "    def train(self, nnArch, mnist=None, lrate=0.001, bSize=100, epochs=10, printStep=5, nSamples=100):\n",
    "    \n",
    "        vae = Vae.VAE(nnArch, lrate=lrate, bSize=bSize)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(nSamples / bSize)\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, _ = mnist.train.next_batch(bSize)\n",
    "                cost = vae.Fit(batch_xs)\n",
    "                avg_cost += cost[1] / nSamples * bSize\n",
    "                if epoch % printStep == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/autoencoders-for-image-reconstruction-in-python-and-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
